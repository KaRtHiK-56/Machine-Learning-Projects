{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tam-Eng-seq2seq.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1d7s0wI5+mXAnk/h03meO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VegetaSan1/Machine-Learning-Projects/blob/main/Tam_Eng_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtkCOTB5njCG"
      },
      "source": [
        "#import the necessary libraries\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "#define the batch size for training\n",
        "batch_size =3 \n",
        "#define the number of epoch for training\n",
        "epochs = 150\n",
        "#define the dimensionality of the encoding process\n",
        "latent_dim =100\n",
        "#define the number of samples to train on\n",
        "num_samples = 150"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0y454E_njcm"
      },
      "source": [
        "#define the file location\n",
        "data_path = 'tam.txt'\n",
        "#define an empty list to store the words/sentences in English\n",
        "input_texts = []\n",
        "#define an empty list to store the characters in Spanish\n",
        "target_texts = []\n",
        "#define a set to store the words/sentences in English\n",
        "#a set data type and not a list is used to avoid repetition of characters\n",
        "input_characters = set()\n",
        "#define a set to store the characters in Spanish\n",
        "target_characters = set()\n",
        "#read the data file and parse by each line\n",
        "with open(data_path,encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    #split each line into the input text, target text and the other unnecessary text\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    #we use tab as the start sequence character for the target, and \\n as end sequence character\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    #append the English words for each text to the empty list\n",
        "    input_texts.append(input_text)\n",
        "    #append the Spanish words for each text to the empty list\n",
        "    target_texts.append(target_text)\n",
        "    #select the letters or words in English\n",
        "    for char in input_text:\n",
        "        #check if the letter is not in the list\n",
        "        if char not in input_characters:\n",
        "            #append the letter that is not on the list\n",
        "            input_characters.add(char)\n",
        "    #select the letters or words in Spanish\n",
        "    for char in target_text:\n",
        "        #check if the letter or word is not in the list\n",
        "        if char not in target_characters:\n",
        "            #append the letter or word that is not on the list\n",
        "            target_characters.add(char)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPDjhk6sonfF",
        "outputId": "c166ab7a-2790-461e-b059-871e1ebdfca4"
      },
      "source": [
        "print(input_text)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He bought a pair of shoes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZHx4uhHoniS",
        "outputId": "b697a71b-7d5f-4e13-8008-99648a68c637"
      },
      "source": [
        "print(target_text)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tநான் ஒரு ஜோடி காலணிகளை வாங்கினேன்\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCFUKAo4oxI7",
        "outputId": "2880016b-c1b8-4d29-f2d2-1a52f437f779"
      },
      "source": [
        "print(input_texts)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I slept.', 'Calm down.', \"I'll walk.\", 'Who is he?', 'Who knows?', 'She smiled.', 'Talk to me!', 'Who is she?', 'Go to sleep.', 'It may rain.', 'She bit him.', 'She hit him.', 'She is kind.', 'She is eight.', 'Where are we?', 'Keep in touch!', 'See you again.', 'Give it to her.', 'I ate too much.', \"I'll see to it.\", \"It's up to you.\", 'Leave it to me.', 'Listen to this!', \"That's the way.\", 'Come and see me.', \"Don't lie to me.\", 'He began to run.', 'He just arrived.', 'He likes to run.', 'How is your dad?', 'I want to sleep.', \"I'm able to run.\", 'Raise your hand.', 'What did he say?', 'When can we eat?', 'Come and help us.', 'He is still here.', 'I have to go now.', 'I know that much.', 'I made a mistake.', 'I walk to school.', \"That's our house.\", 'Those are my CDs.', 'Walk ahead of me.', \"We'll follow you.\", 'Beware of the dog!', 'He came back soon.', 'He has three sons.', 'I know how to ski.', 'I know what to do.', \"I'm kind of happy.\", 'Keep to the right.', 'She began to sing.', 'She decided to go.', 'Do I have to study?', 'He is sure to come.', 'I had to walk home.', 'I have to dress up.', 'I told him to come.', \"I'm short of money.\", 'May I speak to you?', 'She gave it to him.', 'She is kind to him.', 'She sat next to me.', 'Shut up and listen!', 'Tell me what to do.', 'Tom runs very fast.', 'We ran out of food.', 'We started to walk.', 'When does it begin?', 'Are you ready to go?', 'Do you have any gum?', 'Does she play piano?', \"Don't listen to her.\", 'Go and wake Mary up.', 'He seems to know us.', 'I am engaged to her.', 'I have to leave now.', 'I want to go abroad.', \"I'm glad to see you.\", \"I'm proud of my son.\", \"I'm taller than you.\", \"I'm trying to sleep.\", \"It's free of charge.\", \"It's time to get up.\", 'Nobody speaks to me.', 'Roll the ball to me.', 'She boiled the eggs.', 'She danced with him.', 'She gave him a book.', 'She has 2,000 books.', 'This apple is sweet.', 'We swam in the lake.', 'Come home before six.', 'Go and see who it is.', 'I am afraid of bears.', 'I expect him to come.', \"It's a piece of cake.\", 'The boy began to cry.', 'You keep out of this.', 'All of us were silent.', 'Be kind to old people.', 'Beware of pickpockets.', \"Don't drink and drive.\", 'He can read and write.', 'He got a lot of money.', 'He has a lot of money.', 'He is afraid of death.', 'He let go of the rope.', 'I am tired of my work.', 'I got out of the taxi.', 'None of your business.', 'They made fun of Mary.', 'Tom and I are friends.', 'When is your birthday?', 'All of them went there.', 'Can you ride a bicycle?', 'Do you want to be rich?', 'He is afraid of snakes.', 'He is fond of swimming.', 'He went in place of me.', \"He's afraid of the sea.\", \"I'll leave that to you.\", 'It seems she hates you.', 'She got engaged to him.', 'She got married to him.', 'She stood close to him.', \"They're about to leave.\", 'This CD belongs to her.', 'We ran after the thief.', 'What do you plan to do?', 'A square has four sides.', 'Charge it to my account.', 'He asked us to help him.', 'He is known to everyone.', 'He objected to our plan.', 'I just want you to come.', 'I want something to eat.', 'Is he a friend of yours?', 'The news quickly spread.', \"I can't find it anywhere.\", \"I thought you'd be angry.\", 'Please sit here and wait.', 'She went out of the room.', 'Speak slowly and clearly.', 'The sky is full of stars.', 'Come and see me right now.', 'Do you have a lot of pens?', 'Go and sit by your father.', 'He bought a pair of shoes.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHCrnsHZoxLp",
        "outputId": "922489e6-bc80-44ba-ba9b-a68fb9815338"
      },
      "source": [
        "print(target_texts)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\tநான் தூங்கினேன்.\\n', '\\tஅமைதியாக இருங்கள்\\n', '\\tநான் நடப்பேன்.\\n', '\\tஅவன் யார்?\\n', '\\tயாருக்குத் தெரியும்?\\n', '\\tஅவள் சிரித்தாள்\\n', '\\tஎன்னிடம் பேசு\\n', '\\tஅவள் யார்?\\n', '\\tபோய் தூங்கு\\n', '\\tமழை பெய்யலாம்\\n', '\\tஅவள் அவனைக் கடித்தாள்\\n', '\\tஅவள் அவனைக் அடித்தாள்\\n', '\\tஅவள் அன்பானவள்\\n', '\\tஅவளுக்கு எட்டு வயது\\n', '\\tநாம் எங்கே இருக்கிறோம்?\\n', '\\tதொடர்பில் இரு\\n', '\\tமறுபடியும் சந்திப்போம்\\n', '\\tஅவளிடம் கொடு\\n', '\\tநான் நிறைய சாப்பிட்டேன்\\n', '\\tஅதை நான் பார்க்கிறேன்\\n', '\\tஉன் கையில்தான் இருக்கிறது\\n', '\\tஎன்னிடம் விட்டுவிடு\\n', '\\tஇதைக் கேள்\\n', '\\tஅந்த பக்கம்தான் வழி\\n', '\\tஎன்னை வந்து பார்\\n', '\\tஎன்னிடம் பொய் சொல்லாதே\\n', '\\tஅவன் ஓட ஆரம்பித்தான்\\n', '\\tஅவன் இப்பொழுதுதான் வந்தான்\\n', '\\tஅவன் ஓட விருப்பப் படுகிறான்\\n', '\\tதங்களுடைய தந்தையார் எப்படி இருக்கிறார்கள்?\\n', '\\tநான் தூங்க விரும்புகிறேன்\\n', '\\tஎன்னால் ஓட முடிகிறது\\n', '\\tகையைத் தூக்கு\\n', '\\tஅவன் என்ன சொன்னான்?\\n', '\\tஎப்பொழுது நம்மால் சாப்பிட முடியும்\\n', '\\tவா எங்களுக்கு உதவி செய்\\n', '\\tஅவன் இன்னும் இருக்கிறான்\\n', '\\tநான் இப்பொழுது போக வேண்டும்\\n', '\\tஎனக்கு அவ்வளவு தெரியும்.\\n', '\\tநான் ஒரு தவறு செய்தேன்?\\n', '\\tநான் பள்ளிக்கு நடந்து செல்கிறேன்\\n', '\\tஅது எங்களுடைய வீடு\\n', '\\tஅவைகள் என்னுடைய CD கள்\\n', '\\tஎனக்கு முன்னால் நட\\n', '\\tநாங்கள் உன்னைத் பின்பற்றுவோம் (அ) தொடர்வோம்.\\n', '\\tநாய் ஜாக்கிரதை!\\n', '\\tஅவன் சீக்கிரம் திரும்பி வந்தான்\\n', '\\tஅவருக்கு மூன்று மகன்கள்\\n', '\\tஎப்படி பனியில் சறுக்கி விளையாடுவது என்பது எனக்கு தெரியும்\\n', '\\tஎன்ன செய்வது என்பது எனக்குத் தெரியும்\\n', '\\tநான் ஒரு விதமான மகிழ்ச்சியிலிருக்கிறேன்\\n', '\\tவலது பக்கத்தை கடைப் பிடி\\n', '\\tஅவள் பாட ஆரம்பித்தாள்\\n', '\\tஅவள் போகத் தீர்மானித்தாள்\\n', '\\tநான் படிக்க வேண்டுமா?\\n', '\\tஅவன் வருவது நிச்சயம்\\n', '\\tநான் வீட்டிற்கு நடக்க வேண்டியிருந்தது\\n', '\\tநான் ஆடை அணிய வேண்டும்\\n', '\\tநான் அவனை வரச் சொன்னேன்\\n', '\\tஎன்னிடம் பணம் குறைவாக இருக்கிறது\\n', '\\tநான் உன்னிடம் பேசலாமா?\\n', '\\tஅவள் இதை அவனுக்குக் கொடுத்தாள்\\n', '\\tஅவள் அவனிடம் அன்பாக இருக்கிறாள்\\n', '\\tஅவள் எனக்கு அருகில் அமர்ந்தாள்\\n', '\\tவாயை மூடி கவனி\\n', '\\tநான் என்ன செய்ய வேண்டும் என்று சொல்\\n', '\\tடாம் ரொம்ப வேகமாக ஓடுகிறான்\\n', '\\tஎங்களுக்கு உணவு தட்டுப்பாடு ஏற்பட்டது\\n', '\\tநாங்கள் நடக்க ஆரம்பித்தோம்\\n', '\\tஇது எப்பொழுது ஆரம்பிக்கிறது?\\n', '\\tநீங்கள் போகத் தயாராக இருக்கிறீர்களா?\\n', '\\tஉன்னிடம் ஏதாவது பசை இருக்கிறதா?\\n', '\\tஅவள் பியானோ வாசிக்கிறாளோ?\\n', '\\tஅவள் சொல்வதைக் கேட்காதீர்\\n', '\\tபோய் மேரியை எழுப்பு\\n', '\\tஅவனுக்கு நம்மைப் தெரியும் என்று தோன்றுகிறது\\n', '\\tஎனக்கு அவளோடு நிச்சயமாகியிருக்கு\\n', '\\tநான் இப்பொழுது கிளம்ப வேண்டும்\\n', '\\tநான் வெளி நாட்டிற்குச் செல்ல விரும்புகிறேன்\\n', '\\tஉன்னைப் பார்ப்பதில் நான் மகிழ்ச்சி அடைகிறேன்\\n', '\\tஎன் மகனைப் பற்றி பெருமைப் படுகிறேன்\\n', '\\tநான் உன்னை விட உயரமாக இருக்கிறேன்\\n', '\\tநான் தூங்குவதற்கு முயற்சி செய்து கொண்டிருக்கிறேன்\\n', '\\tஇதற்கு கட்டணமில்லை\\n', '\\tதூக்கத்திலிருந்து எழுவதற்கான நேரம் இது\\n', '\\tஎன் கூட யாரும் பேசுவதில்லை\\n', '\\tபந்தை என்னிடம் உருட்டி விடு\\n', '\\tஅவள் முட்டைகளை வேக வைத்தாள்\\n', '\\tஅவள் அவனோடு நடனம் ஆடினாள்\\n', '\\tஅவள் அவனுக்கு ஒரு புத்தகத்தைக் கொடுத்தாள்\\n', '\\tஅவளிடம் 2000 புத்தகங்கள் உள்ளன\\n', '\\tஇந்த ஆப்பிள் இனிப்பாக இருக்கிறது\\n', '\\tஅவன் ஏரியில் நீச்சலடித்தான்\\n', '\\tஆறு மணிக்கு முன்பு வீட் டிற்கு வா\\n', '\\tபோய் யார் என்று பார்\\n', '\\tஎனக்குக் கரடிகளைக கண்டால் பயம்\\n', '\\tஅவன் வருவான் என எதிர் பார்க்கிறேன்\\n', '\\tஇது ஒரு கேக்கின் துண்டு\\n', '\\tஅந்த பையன் அழ ஆரம்பித்தான்\\n', '\\tநீ இதில் தலையிடாதே\\n', '\\tநாங்கள் அனைவரும் அமைதியாக இருந்தோம்\\n', '\\tவயோதிகர்களிடம் அன்பாக இரு\\n', '\\tஜேப்படிகாரர்களிடம் ஜாக்கிரதையாக இருக்கவும்\\n', '\\tகுடித்துவிட்டு வண்டி ஓட்டாதே\\n', '\\tஅவனுக்கு எழுதப் படிக்கத் தெரியும்\\n', '\\tஅவனுக்கு நிறைய பணம் கிடைத்தது\\n', '\\tஅவனிடம் நிறைய பணமிருக்கிறது\\n', '\\tஅவனுக்கு இறந்து போவதென்றால் பயம்\\n', '\\tஅவன் கயிற்றை விட்டான்\\n', '\\tநான் வேலை பளுவினால் சோர்வாகயிருக்கிறேன்\\n', '\\tநான் டாக்ஸியிலிருந்து இறங்கினேன்\\n', '\\tஇது உங்களுக்கு சம்பந்தமில்லாத விஷயம்\\n', '\\tஅவர்கள் மேரியை கிண்டலடித்தார்கள்\\n', '\\tடாமும் நானும் நண்பர்கள்\\n', '\\tஉங்கள் பிறந்த நாள் எப்போது ?\\n', '\\tஅவர்கள் எல்லோரும் அங்கே சென்றார்கள்\\n', '\\tஉங்களுக்கு சைக்கிள் ஓட்டத் தெரியுமா?\\n', '\\tநீ பணக்காரராக விருப்பமா?\\n', '\\tஅவர்களுக்கு பாம்புகள் என்றால் பயம்\\n', '\\tஅவனுக்கு நீச்சல் மீது பற்று உண்டு\\n', '\\tஅவன் எனக்குப் பதிலாக சேன்றான்\\n', '\\tஅவனுக்குக் கடல் என்றால் பயம்\\n', '\\tநான் அதை உன்னிடம் விட்டு விடுகிறேன்\\n', '\\tஅவள் உன்னை வெறுக்கிற மாதிரி தெரிகிறது\\n', '\\tஅவள் அவனுக்கு நிச்சயிக்கப் பட்டாள்\\n', '\\tஅவள் அவனுக்கு திருமணம் செய்து வைக்கப் பட்டாள்\\n', '\\tஅவனுக்கு நெருக்கமாக நின்றாள்\\n', '\\tஅவர்கள் கிளம்ப இருக்கிறார்கள்\\n', '\\tஇந்த சீடி அவளுக்குச் சொந்தமானது\\n', '\\tநாங்கள் திருடனுக்குப் பின்னால் ஓடினோம்\\n', '\\tநீ என்ன செய்யத் திட்டமிட்டிருக்கிறாய்\\n', '\\tஒரு சதுரத்திற்கு நான்கு பக்கங்கள் உள்ளன\\n', '\\tஎன்னுடைய கணக்கிற்கு மாற்று\\n', '\\tஎங்களை உதவி செய்யும்படி கேட்டான்\\n', '\\tஅவன் ஒவ்வொருவருக்கும் அறிமுகமானவன்\\n', '\\tஎங்களுடைய திட்டத்திற்கு எதிர்ப்புத் தெரிவித்தான்\\n', '\\tநீ வர வேண்டுமென விரும்புகிறேன்\\n', '\\tஎனக்கு சாப்பிட ஏதாவது வேண்டும்\\n', '\\tஅவர் உங்களுடைய நண்பரா?\\n', '\\tசெய்தி வேகமாக பரவியது\\n', '\\tஇது எங்கே இருக்கு என்று என்னால் கண்டுபிடிக்க முடியவில்லை.\\n', '\\tநீ கோபமாக இருப்பாய் என்று எண்ணினேன்.\\n', '\\tஇங்கே அமருங்கள்,தயவு செயது காத்திருங்கள்\\n', '\\tஅவள் அறையை விட்டு வெளியே சென்றாள்\\n', '\\tமெதுவாகவும் தெளிவாகவும் பேசுங்கள்\\n', '\\tவானம் முழுவதும் நட்சத்திரங்கள் இருக்கின்றன\\n', '\\tஉடனே வந்து என்னைப் பார்க்கவும்\\n', '\\tஉன்னிடம் நிறைய பேனாக்கள் இருக்கின்றனவா?\\n', '\\tபோய் உன் தந்தையருகில் அமரவும்\\n', '\\tநான் ஒரு ஜோடி காலணிகளை வாங்கினேன்\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUoAsVwJnje5",
        "outputId": "7277c3a4-36bb-4a61-a128-c1f767041ffd"
      },
      "source": [
        "print(input_characters)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'R', 'h', 'p', 'o', 'e', 'k', 'n', \"'\", 'W', 'K', 'I', 'y', 'j', 'x', '0', '?', 'l', 'm', 'd', 'B', 'i', '2', 'S', 'u', '!', 'v', 'G', 't', 'H', 's', 'b', 'r', 'A', 'N', 'w', 'L', 'D', ',', 'Y', 'P', 'g', 'q', 'c', 'M', 'T', 'C', 'f', ' ', '.', 'a'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vqfzy5gInjh0",
        "outputId": "4e0210a0-84a8-4bf5-8df0-bd000c08f679"
      },
      "source": [
        "print(target_characters)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ல', 'ூ', 'ஷ', 'ு', '(', 'ப', ')', 'ஓ', 'ா', 'ங', 'ம', 'உ', '0', 'ழ', 'ய', 'ை', 'ே', '?', 'ஒ', 'ச', 'வ', 'த', '2', 'ந', '!', 'ள', 'க', 'ன', 'ோ', 'அ', 'ஏ', '\\t', 'D', ',', 'எ', 'ர', 'ொ', 'ண', 'ெ', 'ட', 'C', '\\n', 'இ', 'ீ', ' ', 'ி', '.', 'ற', 'ஜ', 'ஸ', '்', 'ஆ'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW4eQu8Injj7",
        "outputId": "928c2a59-c17c-4c70-f6f5-fa6f52d407a9"
      },
      "source": [
        "#define the sorted list of English words\n",
        "input_characters = sorted(list(input_characters))\n",
        "#define the sorted list of Spanish words\n",
        "target_characters = sorted(list(target_characters))\n",
        "#define the number of English words\n",
        "num_encoder_tokens = len(input_characters)\n",
        "#define the number of Spanish words\n",
        "num_decoder_tokens = len(target_characters)\n",
        "#define the maximum length of the English sentences\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "#define the maximum length of the Spanish sentences\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs\", max_decoder_seq_length)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 150\n",
            "Number of unique input tokens: 50\n",
            "Number of unique output tokens: 52\n",
            "Max sequence length for inputs: 26\n",
            "Max sequence length for outputs 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUJL6pBOnjmX"
      },
      "source": [
        "#index each characters in English\n",
        "input_token_index = dict(\n",
        "[(char, i) for i, char in enumerate(input_characters)])\n",
        "#index each characters in Spanish\n",
        "target_token_index = dict(\n",
        "[(char, i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqB2yeNmpBq5",
        "outputId": "43b2478c-1da3-49b5-c2d0-76236cabdd2b"
      },
      "source": [
        "print(input_token_index)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, '!': 1, \"'\": 2, ',': 3, '.': 4, '0': 5, '2': 6, '?': 7, 'A': 8, 'B': 9, 'C': 10, 'D': 11, 'G': 12, 'H': 13, 'I': 14, 'K': 15, 'L': 16, 'M': 17, 'N': 18, 'P': 19, 'R': 20, 'S': 21, 'T': 22, 'W': 23, 'Y': 24, 'a': 25, 'b': 26, 'c': 27, 'd': 28, 'e': 29, 'f': 30, 'g': 31, 'h': 32, 'i': 33, 'j': 34, 'k': 35, 'l': 36, 'm': 37, 'n': 38, 'o': 39, 'p': 40, 'q': 41, 'r': 42, 's': 43, 't': 44, 'u': 45, 'v': 46, 'w': 47, 'x': 48, 'y': 49}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW3dllJ_pBtl",
        "outputId": "c338019c-e613-4c81-a3c3-2235676392fd"
      },
      "source": [
        "print(target_token_index)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '(': 4, ')': 5, ',': 6, '.': 7, '0': 8, '2': 9, '?': 10, 'C': 11, 'D': 12, 'அ': 13, 'ஆ': 14, 'இ': 15, 'உ': 16, 'எ': 17, 'ஏ': 18, 'ஒ': 19, 'ஓ': 20, 'க': 21, 'ங': 22, 'ச': 23, 'ஜ': 24, 'ட': 25, 'ண': 26, 'த': 27, 'ந': 28, 'ன': 29, 'ப': 30, 'ம': 31, 'ய': 32, 'ர': 33, 'ற': 34, 'ல': 35, 'ள': 36, 'ழ': 37, 'வ': 38, 'ஷ': 39, 'ஸ': 40, 'ா': 41, 'ி': 42, 'ீ': 43, 'ு': 44, 'ூ': 45, 'ெ': 46, 'ே': 47, 'ை': 48, 'ொ': 49, 'ோ': 50, '்': 51}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ufU0xa7njo4"
      },
      "source": [
        "#define the input data of the encoder as a 3-dimensional matrix populated with zeros\n",
        "#the shape of the matrix is the length of the input text by the length of the max encoder by the number of encoder characters\n",
        "#the np.zeros() function takes an argument of the specified dtype. Here we use float32\n",
        "encoder_input_data = np.zeros(\n",
        "(len(input_texts), max_encoder_seq_length, num_encoder_tokens\n",
        "), dtype='float32')\n",
        "#define the input data of the decoder as a 3-dimensional matrix populated with zeros\n",
        "decoder_input_data = np.zeros(\n",
        "(len(input_texts), max_decoder_seq_length, num_decoder_tokens\n",
        "), dtype='float32')\n",
        "#define the target data of the decoder as a 3-dimensional matrix populated with zeros\n",
        "decoder_target_data = np.zeros(\n",
        "(len(input_texts), max_decoder_seq_length, num_decoder_tokens\n",
        "), dtype='float32')"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tuJOp3ynjqx"
      },
      "source": [
        "#parse the input and output texts\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        #define that the decoder_target_data is one time step ahead of the decoder_input_data by \n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            # define the decoder_target_data to be ahead by one timestep and will not include the first character\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
        "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHNiijD-pS-a",
        "outputId": "d979318c-cfd7-42cf-8474-21a2536f7465"
      },
      "source": [
        "encoder_input_data[0].shape"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5bsd_FnpX3p",
        "outputId": "174a629d-5bbf-442f-aa40-6326307107b0"
      },
      "source": [
        "encoder_input_data.shape"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 26, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je2zq01onjtP"
      },
      "source": [
        "#define an input of the encoder with length as the number of encoder tokens\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "#instantiate the LSTM model\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "#define the outputs and states of the encoder\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "#disregard encoder_outputs and keep only the states\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRUVY4kvnjvn",
        "outputId": "4c714eef-79b4-417a-9c28-526edcdd6c44"
      },
      "source": [
        "#define an input of the encoder with length as the number of encoder tokens\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "#define the LSTM model for the decoder setting the return sequences and return state to True\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "#define only the decoder output for the training model. The states are only needed in the inference model\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "#define the training model which requires the encoder_input_data and decoder_input_data to return the decoder_target_data\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "#Train the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "         batch_size=batch_size,\n",
        "         epochs=epochs,\n",
        "         validation_split=0.2)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "40/40 [==============================] - 6s 55ms/step - loss: 2.5953 - accuracy: 0.5172 - val_loss: 2.3863 - val_accuracy: 0.4661\n",
            "Epoch 2/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 1.7346 - accuracy: 0.5838 - val_loss: 2.0334 - val_accuracy: 0.4621\n",
            "Epoch 3/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 1.6140 - accuracy: 0.5888 - val_loss: 1.9661 - val_accuracy: 0.4644\n",
            "Epoch 4/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 1.5165 - accuracy: 0.5993 - val_loss: 1.9092 - val_accuracy: 0.4785\n",
            "Epoch 5/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 1.4720 - accuracy: 0.6072 - val_loss: 1.8637 - val_accuracy: 0.4847\n",
            "Epoch 6/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 1.4351 - accuracy: 0.6165 - val_loss: 1.8275 - val_accuracy: 0.5073\n",
            "Epoch 7/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 1.4009 - accuracy: 0.6355 - val_loss: 1.7960 - val_accuracy: 0.5237\n",
            "Epoch 8/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 1.3650 - accuracy: 0.6451 - val_loss: 1.7564 - val_accuracy: 0.5350\n",
            "Epoch 9/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 1.3256 - accuracy: 0.6564 - val_loss: 1.7091 - val_accuracy: 0.5412\n",
            "Epoch 10/150\n",
            "40/40 [==============================] - 1s 32ms/step - loss: 1.2861 - accuracy: 0.6612 - val_loss: 1.6714 - val_accuracy: 0.5480\n",
            "Epoch 11/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 1.2440 - accuracy: 0.6648 - val_loss: 1.6189 - val_accuracy: 0.5559\n",
            "Epoch 12/150\n",
            "40/40 [==============================] - 1s 32ms/step - loss: 1.2030 - accuracy: 0.6742 - val_loss: 1.5736 - val_accuracy: 0.5571\n",
            "Epoch 13/150\n",
            "40/40 [==============================] - 1s 32ms/step - loss: 1.1708 - accuracy: 0.6799 - val_loss: 1.5326 - val_accuracy: 0.5729\n",
            "Epoch 14/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 1.1425 - accuracy: 0.6934 - val_loss: 1.5126 - val_accuracy: 0.5887\n",
            "Epoch 15/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 1.1100 - accuracy: 0.6979 - val_loss: 1.4735 - val_accuracy: 0.5989\n",
            "Epoch 16/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 1.0832 - accuracy: 0.7092 - val_loss: 1.4460 - val_accuracy: 0.6068\n",
            "Epoch 17/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 1.0563 - accuracy: 0.7153 - val_loss: 1.4220 - val_accuracy: 0.6000\n",
            "Epoch 18/150\n",
            "40/40 [==============================] - 1s 32ms/step - loss: 1.0343 - accuracy: 0.7195 - val_loss: 1.4042 - val_accuracy: 0.6158\n",
            "Epoch 19/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 1.0125 - accuracy: 0.7223 - val_loss: 1.3941 - val_accuracy: 0.6147\n",
            "Epoch 20/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.9893 - accuracy: 0.7264 - val_loss: 1.3664 - val_accuracy: 0.6147\n",
            "Epoch 21/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.9696 - accuracy: 0.7285 - val_loss: 1.3531 - val_accuracy: 0.6220\n",
            "Epoch 22/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.9481 - accuracy: 0.7364 - val_loss: 1.3294 - val_accuracy: 0.6311\n",
            "Epoch 23/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.9311 - accuracy: 0.7404 - val_loss: 1.3220 - val_accuracy: 0.6266\n",
            "Epoch 24/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.9202 - accuracy: 0.7391 - val_loss: 1.2927 - val_accuracy: 0.6277\n",
            "Epoch 25/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.8982 - accuracy: 0.7445 - val_loss: 1.2816 - val_accuracy: 0.6288\n",
            "Epoch 26/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.8854 - accuracy: 0.7492 - val_loss: 1.2841 - val_accuracy: 0.6254\n",
            "Epoch 27/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.8666 - accuracy: 0.7531 - val_loss: 1.2666 - val_accuracy: 0.6379\n",
            "Epoch 28/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.8480 - accuracy: 0.7547 - val_loss: 1.2582 - val_accuracy: 0.6390\n",
            "Epoch 29/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.8361 - accuracy: 0.7597 - val_loss: 1.2660 - val_accuracy: 0.6412\n",
            "Epoch 30/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.8229 - accuracy: 0.7627 - val_loss: 1.2412 - val_accuracy: 0.6452\n",
            "Epoch 31/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.8073 - accuracy: 0.7694 - val_loss: 1.2452 - val_accuracy: 0.6475\n",
            "Epoch 32/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.7939 - accuracy: 0.7691 - val_loss: 1.2407 - val_accuracy: 0.6424\n",
            "Epoch 33/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.7836 - accuracy: 0.7726 - val_loss: 1.2424 - val_accuracy: 0.6508\n",
            "Epoch 34/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.7662 - accuracy: 0.7818 - val_loss: 1.2228 - val_accuracy: 0.6508\n",
            "Epoch 35/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.7560 - accuracy: 0.7802 - val_loss: 1.2188 - val_accuracy: 0.6588\n",
            "Epoch 36/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.7462 - accuracy: 0.7835 - val_loss: 1.2269 - val_accuracy: 0.6508\n",
            "Epoch 37/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.7372 - accuracy: 0.7870 - val_loss: 1.2410 - val_accuracy: 0.6542\n",
            "Epoch 38/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.7241 - accuracy: 0.7891 - val_loss: 1.2410 - val_accuracy: 0.6520\n",
            "Epoch 39/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.7057 - accuracy: 0.7945 - val_loss: 1.2336 - val_accuracy: 0.6576\n",
            "Epoch 40/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.6954 - accuracy: 0.7989 - val_loss: 1.2203 - val_accuracy: 0.6571\n",
            "Epoch 41/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.6870 - accuracy: 0.8001 - val_loss: 1.2135 - val_accuracy: 0.6616\n",
            "Epoch 42/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.6770 - accuracy: 0.8007 - val_loss: 1.2167 - val_accuracy: 0.6548\n",
            "Epoch 43/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.6656 - accuracy: 0.8058 - val_loss: 1.2283 - val_accuracy: 0.6627\n",
            "Epoch 44/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.6508 - accuracy: 0.8110 - val_loss: 1.2282 - val_accuracy: 0.6582\n",
            "Epoch 45/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.6498 - accuracy: 0.8100 - val_loss: 1.2217 - val_accuracy: 0.6503\n",
            "Epoch 46/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.6303 - accuracy: 0.8169 - val_loss: 1.2383 - val_accuracy: 0.6588\n",
            "Epoch 47/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.6182 - accuracy: 0.8186 - val_loss: 1.2517 - val_accuracy: 0.6565\n",
            "Epoch 48/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.6058 - accuracy: 0.8229 - val_loss: 1.2444 - val_accuracy: 0.6576\n",
            "Epoch 49/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.5896 - accuracy: 0.8281 - val_loss: 1.2466 - val_accuracy: 0.6588\n",
            "Epoch 50/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.5875 - accuracy: 0.8284 - val_loss: 1.2945 - val_accuracy: 0.6497\n",
            "Epoch 51/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.5757 - accuracy: 0.8343 - val_loss: 1.2533 - val_accuracy: 0.6492\n",
            "Epoch 52/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.5609 - accuracy: 0.8371 - val_loss: 1.2809 - val_accuracy: 0.6525\n",
            "Epoch 53/150\n",
            "40/40 [==============================] - 2s 38ms/step - loss: 0.5575 - accuracy: 0.8370 - val_loss: 1.2691 - val_accuracy: 0.6565\n",
            "Epoch 54/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.5498 - accuracy: 0.8390 - val_loss: 1.2726 - val_accuracy: 0.6571\n",
            "Epoch 55/150\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.5284 - accuracy: 0.8444 - val_loss: 1.2657 - val_accuracy: 0.6638\n",
            "Epoch 56/150\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.5199 - accuracy: 0.8483 - val_loss: 1.2809 - val_accuracy: 0.6616\n",
            "Epoch 57/150\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.5362 - accuracy: 0.8499 - val_loss: 1.3723 - val_accuracy: 0.6492\n",
            "Epoch 58/150\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.5563 - accuracy: 0.8336 - val_loss: 1.2775 - val_accuracy: 0.6520\n",
            "Epoch 59/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.5001 - accuracy: 0.8518 - val_loss: 1.2854 - val_accuracy: 0.6621\n",
            "Epoch 60/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.4798 - accuracy: 0.8603 - val_loss: 1.3130 - val_accuracy: 0.6571\n",
            "Epoch 61/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.4690 - accuracy: 0.8667 - val_loss: 1.3142 - val_accuracy: 0.6576\n",
            "Epoch 62/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.4579 - accuracy: 0.8679 - val_loss: 1.3282 - val_accuracy: 0.6520\n",
            "Epoch 63/150\n",
            "40/40 [==============================] - 2s 38ms/step - loss: 0.4530 - accuracy: 0.8695 - val_loss: 1.3213 - val_accuracy: 0.6548\n",
            "Epoch 64/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.4554 - accuracy: 0.8685 - val_loss: 1.3325 - val_accuracy: 0.6559\n",
            "Epoch 65/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.4348 - accuracy: 0.8767 - val_loss: 1.3484 - val_accuracy: 0.6520\n",
            "Epoch 66/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.4279 - accuracy: 0.8785 - val_loss: 1.3513 - val_accuracy: 0.6531\n",
            "Epoch 67/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.4213 - accuracy: 0.8781 - val_loss: 1.3571 - val_accuracy: 0.6531\n",
            "Epoch 68/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.4096 - accuracy: 0.8843 - val_loss: 1.3686 - val_accuracy: 0.6537\n",
            "Epoch 69/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.3962 - accuracy: 0.8907 - val_loss: 1.3827 - val_accuracy: 0.6548\n",
            "Epoch 70/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.3934 - accuracy: 0.8890 - val_loss: 1.3875 - val_accuracy: 0.6497\n",
            "Epoch 71/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.3872 - accuracy: 0.8898 - val_loss: 1.3968 - val_accuracy: 0.6593\n",
            "Epoch 72/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.3856 - accuracy: 0.8900 - val_loss: 1.4048 - val_accuracy: 0.6503\n",
            "Epoch 73/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.3705 - accuracy: 0.8982 - val_loss: 1.4123 - val_accuracy: 0.6531\n",
            "Epoch 74/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.3687 - accuracy: 0.8975 - val_loss: 1.4256 - val_accuracy: 0.6514\n",
            "Epoch 75/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.3637 - accuracy: 0.9004 - val_loss: 1.4426 - val_accuracy: 0.6469\n",
            "Epoch 76/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.3501 - accuracy: 0.9040 - val_loss: 1.4372 - val_accuracy: 0.6480\n",
            "Epoch 77/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.3336 - accuracy: 0.9099 - val_loss: 1.4646 - val_accuracy: 0.6531\n",
            "Epoch 78/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.3332 - accuracy: 0.9086 - val_loss: 1.4679 - val_accuracy: 0.6446\n",
            "Epoch 79/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.3258 - accuracy: 0.9106 - val_loss: 1.4745 - val_accuracy: 0.6503\n",
            "Epoch 80/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.3156 - accuracy: 0.9167 - val_loss: 1.4797 - val_accuracy: 0.6458\n",
            "Epoch 81/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.3060 - accuracy: 0.9215 - val_loss: 1.4937 - val_accuracy: 0.6525\n",
            "Epoch 82/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.3084 - accuracy: 0.9220 - val_loss: 1.5113 - val_accuracy: 0.6525\n",
            "Epoch 83/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.3969 - accuracy: 0.8843 - val_loss: 1.4665 - val_accuracy: 0.6441\n",
            "Epoch 84/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.3650 - accuracy: 0.8949 - val_loss: 1.4591 - val_accuracy: 0.6542\n",
            "Epoch 85/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.3310 - accuracy: 0.9041 - val_loss: 1.4750 - val_accuracy: 0.6599\n",
            "Epoch 86/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.2960 - accuracy: 0.9229 - val_loss: 1.4815 - val_accuracy: 0.6571\n",
            "Epoch 87/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.2867 - accuracy: 0.9266 - val_loss: 1.4961 - val_accuracy: 0.6497\n",
            "Epoch 88/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.2764 - accuracy: 0.9306 - val_loss: 1.4996 - val_accuracy: 0.6492\n",
            "Epoch 89/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.2607 - accuracy: 0.9383 - val_loss: 1.5205 - val_accuracy: 0.6424\n",
            "Epoch 90/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.2521 - accuracy: 0.9398 - val_loss: 1.5322 - val_accuracy: 0.6441\n",
            "Epoch 91/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.2492 - accuracy: 0.9410 - val_loss: 1.5631 - val_accuracy: 0.6435\n",
            "Epoch 92/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.2572 - accuracy: 0.9369 - val_loss: 1.5807 - val_accuracy: 0.6373\n",
            "Epoch 93/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.2474 - accuracy: 0.9384 - val_loss: 1.5793 - val_accuracy: 0.6458\n",
            "Epoch 94/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.2419 - accuracy: 0.9444 - val_loss: 1.5772 - val_accuracy: 0.6452\n",
            "Epoch 95/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.2353 - accuracy: 0.9445 - val_loss: 1.5877 - val_accuracy: 0.6452\n",
            "Epoch 96/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.2259 - accuracy: 0.9456 - val_loss: 1.5860 - val_accuracy: 0.6424\n",
            "Epoch 97/150\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.2175 - accuracy: 0.9516 - val_loss: 1.6195 - val_accuracy: 0.6497\n",
            "Epoch 98/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.2120 - accuracy: 0.9525 - val_loss: 1.6239 - val_accuracy: 0.6429\n",
            "Epoch 99/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.2025 - accuracy: 0.9564 - val_loss: 1.6260 - val_accuracy: 0.6480\n",
            "Epoch 100/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1997 - accuracy: 0.9583 - val_loss: 1.6683 - val_accuracy: 0.6367\n",
            "Epoch 101/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.2008 - accuracy: 0.9568 - val_loss: 1.6542 - val_accuracy: 0.6446\n",
            "Epoch 102/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1972 - accuracy: 0.9559 - val_loss: 1.6805 - val_accuracy: 0.6384\n",
            "Epoch 103/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.2016 - accuracy: 0.9532 - val_loss: 1.6925 - val_accuracy: 0.6401\n",
            "Epoch 104/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.1893 - accuracy: 0.9573 - val_loss: 1.7006 - val_accuracy: 0.6452\n",
            "Epoch 105/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1798 - accuracy: 0.9626 - val_loss: 1.6993 - val_accuracy: 0.6395\n",
            "Epoch 106/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1772 - accuracy: 0.9644 - val_loss: 1.7167 - val_accuracy: 0.6412\n",
            "Epoch 107/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.1784 - accuracy: 0.9627 - val_loss: 1.7202 - val_accuracy: 0.6384\n",
            "Epoch 108/150\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.1820 - accuracy: 0.9596 - val_loss: 1.7337 - val_accuracy: 0.6424\n",
            "Epoch 109/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1753 - accuracy: 0.9629 - val_loss: 1.7408 - val_accuracy: 0.6333\n",
            "Epoch 110/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1632 - accuracy: 0.9672 - val_loss: 1.7182 - val_accuracy: 0.6446\n",
            "Epoch 111/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.1602 - accuracy: 0.9671 - val_loss: 1.7511 - val_accuracy: 0.6435\n",
            "Epoch 112/150\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.1592 - accuracy: 0.9681 - val_loss: 1.7545 - val_accuracy: 0.6424\n",
            "Epoch 113/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.1521 - accuracy: 0.9713 - val_loss: 1.7770 - val_accuracy: 0.6339\n",
            "Epoch 114/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1432 - accuracy: 0.9718 - val_loss: 1.7888 - val_accuracy: 0.6469\n",
            "Epoch 115/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1381 - accuracy: 0.9744 - val_loss: 1.8099 - val_accuracy: 0.6373\n",
            "Epoch 116/150\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.1386 - accuracy: 0.9719 - val_loss: 1.8009 - val_accuracy: 0.6390\n",
            "Epoch 117/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1332 - accuracy: 0.9753 - val_loss: 1.8266 - val_accuracy: 0.6424\n",
            "Epoch 118/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.1280 - accuracy: 0.9788 - val_loss: 1.8562 - val_accuracy: 0.6311\n",
            "Epoch 119/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1320 - accuracy: 0.9757 - val_loss: 1.8418 - val_accuracy: 0.6322\n",
            "Epoch 120/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.1219 - accuracy: 0.9782 - val_loss: 1.8684 - val_accuracy: 0.6367\n",
            "Epoch 121/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1331 - accuracy: 0.9733 - val_loss: 1.8525 - val_accuracy: 0.6362\n",
            "Epoch 122/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1347 - accuracy: 0.9737 - val_loss: 1.8412 - val_accuracy: 0.6322\n",
            "Epoch 123/150\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.1288 - accuracy: 0.9750 - val_loss: 1.9128 - val_accuracy: 0.6294\n",
            "Epoch 124/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1212 - accuracy: 0.9781 - val_loss: 1.8722 - val_accuracy: 0.6384\n",
            "Epoch 125/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1126 - accuracy: 0.9801 - val_loss: 1.8825 - val_accuracy: 0.6362\n",
            "Epoch 126/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1078 - accuracy: 0.9823 - val_loss: 1.9202 - val_accuracy: 0.6311\n",
            "Epoch 127/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1010 - accuracy: 0.9839 - val_loss: 1.9151 - val_accuracy: 0.6424\n",
            "Epoch 128/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.0946 - accuracy: 0.9864 - val_loss: 1.9357 - val_accuracy: 0.6345\n",
            "Epoch 129/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.0923 - accuracy: 0.9857 - val_loss: 1.9397 - val_accuracy: 0.6339\n",
            "Epoch 130/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.0997 - accuracy: 0.9829 - val_loss: 1.9744 - val_accuracy: 0.6299\n",
            "Epoch 131/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1130 - accuracy: 0.9767 - val_loss: 1.9441 - val_accuracy: 0.6316\n",
            "Epoch 132/150\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.1228 - accuracy: 0.9756 - val_loss: 1.9624 - val_accuracy: 0.6299\n",
            "Epoch 133/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.3092 - accuracy: 0.9120 - val_loss: 1.8238 - val_accuracy: 0.6181\n",
            "Epoch 134/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.5077 - accuracy: 0.8504 - val_loss: 1.6011 - val_accuracy: 0.6469\n",
            "Epoch 135/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.2768 - accuracy: 0.9168 - val_loss: 1.6305 - val_accuracy: 0.6514\n",
            "Epoch 136/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1971 - accuracy: 0.9500 - val_loss: 1.6982 - val_accuracy: 0.6520\n",
            "Epoch 137/150\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1496 - accuracy: 0.9688 - val_loss: 1.7599 - val_accuracy: 0.6492\n",
            "Epoch 138/150\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.1244 - accuracy: 0.9778 - val_loss: 1.7700 - val_accuracy: 0.6531\n",
            "Epoch 139/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.1096 - accuracy: 0.9816 - val_loss: 1.8109 - val_accuracy: 0.6503\n",
            "Epoch 140/150\n",
            "40/40 [==============================] - 2s 40ms/step - loss: 0.0997 - accuracy: 0.9866 - val_loss: 1.8429 - val_accuracy: 0.6469\n",
            "Epoch 141/150\n",
            "40/40 [==============================] - 2s 39ms/step - loss: 0.0929 - accuracy: 0.9864 - val_loss: 1.8662 - val_accuracy: 0.6446\n",
            "Epoch 142/150\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.0884 - accuracy: 0.9867 - val_loss: 1.8943 - val_accuracy: 0.6486\n",
            "Epoch 143/150\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.0834 - accuracy: 0.9894 - val_loss: 1.8968 - val_accuracy: 0.6469\n",
            "Epoch 144/150\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.0789 - accuracy: 0.9897 - val_loss: 1.9307 - val_accuracy: 0.6441\n",
            "Epoch 145/150\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.0744 - accuracy: 0.9900 - val_loss: 1.9523 - val_accuracy: 0.6429\n",
            "Epoch 146/150\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.0724 - accuracy: 0.9900 - val_loss: 1.9599 - val_accuracy: 0.6435\n",
            "Epoch 147/150\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.0707 - accuracy: 0.9897 - val_loss: 1.9705 - val_accuracy: 0.6407\n",
            "Epoch 148/150\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.0680 - accuracy: 0.9911 - val_loss: 1.9795 - val_accuracy: 0.6469\n",
            "Epoch 149/150\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.0653 - accuracy: 0.9914 - val_loss: 1.9830 - val_accuracy: 0.6446\n",
            "Epoch 150/150\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.0629 - accuracy: 0.9921 - val_loss: 2.0113 - val_accuracy: 0.6367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5b29d5ae90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK0bFi9_njxx"
      },
      "source": [
        "#define the decoder input state as  a list of the hidden and cell state\n",
        "encoder_model=Model(encoder_inputs,encoder_states)\n",
        "decoder_state_input_h=Input(shape=(latent_dim,))\n",
        "decoder_state_input_c=Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "#define the decoder output\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "#define the decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + decoder_states_inputs, \n",
        "    [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# Reverse-lookup token index to decode sequence back to something readable\n",
        "reverse_input_char_index = dict(\n",
        "(i, char) for char, i in input_token_index.items()\n",
        ")\n",
        "reverse_target_char_index = dict(\n",
        "(i, char) for char, i in target_token_index.items()\n",
        ")"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bipzXZkNnj2e"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    #encode the input as state vectors\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    \n",
        "    #generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    #populate the first character of target sequence with the start character\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "    \n",
        "    #sampling loop for a batch of sequences\n",
        "    #to simplify, we use batch size of 1\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "        [target_seq] + states_value\n",
        "        )\n",
        "        \n",
        "        #sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "        \n",
        "        #exit condition: either hit max length or find stop character\n",
        "        if (len(decoded_sentence) > max_decoder_seq_length or sampled_char == '\\n'):\n",
        "            stop_condition = True\n",
        "            \n",
        "        #update the target sequence (of length 1)\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "        \n",
        "        #update states\n",
        "        states_value = [h, c]\n",
        "    \n",
        "    return decoded_sentence"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhizKuHdnj4t",
        "outputId": "db22309a-3a84-4f8b-953c-f4a722e27a18"
      },
      "source": [
        "for seq_index in range(10):\n",
        "    #take one sequence (part of the training set) for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    #call the function\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print()\n",
        "    print(f\"Input sentence: {input_texts[seq_index]}\")\n",
        "    print(f\"Decoded sentence: {decoded_sentence}\")"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input sentence: I slept.\n",
            "Decoded sentence: நான் தூங்கினேன்.\n",
            "\n",
            "\n",
            "Input sentence: Calm down.\n",
            "Decoded sentence: அமைதியாக இருங்கள்\n",
            "\n",
            "\n",
            "Input sentence: I'll walk.\n",
            "Decoded sentence: நான் நடப்பேன்.\n",
            "\n",
            "\n",
            "Input sentence: Who is he?\n",
            "Decoded sentence: அவன் யார்?\n",
            "\n",
            "\n",
            "Input sentence: Who knows?\n",
            "Decoded sentence: யாருக்குத் தெரியும்?\n",
            "\n",
            "\n",
            "Input sentence: She smiled.\n",
            "Decoded sentence: அவள் அவனைக் அடித்தாள்\n",
            "\n",
            "\n",
            "Input sentence: Talk to me!\n",
            "Decoded sentence: என்னிடம் பேசு\n",
            "\n",
            "\n",
            "Input sentence: Who is she?\n",
            "Decoded sentence: அவள் யார்?\n",
            "\n",
            "\n",
            "Input sentence: Go to sleep.\n",
            "Decoded sentence: போய் தூங்கு\n",
            "\n",
            "\n",
            "Input sentence: It may rain.\n",
            "Decoded sentence: நான் படிக்கி சேரியாம்\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASRLGuYBnj6k"
      },
      "source": [
        ""
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PyFs65cnj8p"
      },
      "source": [
        ""
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCnA4lNnnj-j"
      },
      "source": [
        ""
      ],
      "execution_count": 135,
      "outputs": []
    }
  ]
}